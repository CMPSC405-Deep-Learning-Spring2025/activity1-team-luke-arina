## Names: Luke Barker, Arina Otbliesk

### Performance

Did the network's output make sense?
How could you adjust weights or activation functions to improve accuracy?
What did you notice about how small changes (e.g., weights) affect outcomes?

Our networks output made sense because the results we got connected to the weights we created and the numbers we set in our simulation. Our network basically decided if we want to eat food based of 3 parameters: 
1) how hungry w are
2) how healthy the food it
3) how appetizing this food looks

Accuracy of this network can be improved by adding more weights and adding more coplexity to it, also customizing it more towards 1 person, instead of our agreed opinion.

After running our first simulation with the peanut butter and jelly sandwiches, we ran it with another food and changed the numbers, and our ouput changed. We noticed that based on the weight, the changes to the input values are not equal because they are weighted differently.

### Ethics

What potential biases or ethical considerations could arise in your example scenario?

In our example, all of the input values are biased to the individual person. For example, one person could think one thing is healthier or more appetizing than another person.

### Reflection

What was easy to understand about the neural network?
What challenges did they face?

The easiest part about figuring out how neural networks work was creating the weights and inputs for our application. The challenge was making sure that our activation function was correct and that it was producing an output that was acceptable. 

<img width="501" alt="Screenshot 2025-01-17 at 9 10 25â€¯AM" src="https://github.com/user-attachments/assets/3a8d3728-bb20-4b34-bf3e-bbbc938036ac" />
